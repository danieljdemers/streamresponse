# For a time scale, use roughly May 1 - Nov 1, and then add some time because the first and last storm do not always extract fully and correctly (due to no previous/next storm identification)
# DOY 120-305 is April 30 - Nov 1, which covers just over half a year
#-----USER INPUTS
#-----Identify the LoVoTECS Site
site1 = "CBU"
#---Define the time range (UTC, 4 digit year, 24hr)
	begin.month = 4
	begin.day = 1
	begin.year = 2013
	begin.hour = 0
	begin.minute = 0
	begin.second = 0
	end.month = 11
	end.day = 30
	end.year = 2013
	end.hour = 0
	end.minute = 0
	end.second = 0
#-----Direct to the folders that hold the precip data and sensor data
	#-----DAN CFE/CHARON SERVER-----
		Precipfolder = ("/home/djd1013/inputdata")
		Sensorfolder = ("/home/djd1013/inputdata")
		Run.Save = ("/home/djd1013/outputdata")
#-----Packages
library(Kendall)
library(zyp)
library(lattice)
library(ggplot2)
library(matrixStats)
library(compiler)
#-----END OF USER INPUTS

## compile
entire.code <- function(iterations){

# VARIABLE PARAMETERS BEGIN
n = iterations*1
##To find implementation throughout this script, search "parameter _" (Example: "parameter b")
a = sample((0):(5), n, replace=T) ##minimum amount of total precip for a storm to be considered a storm event 0mm-5mm
b = sample((12*60*60):(48*60*60), n, replace=T) ##time between storms (12-48 hr range)
## c is not assigned as an object because it is a function in R
d = sample((0):(48*60*60), n, replace=T) ##time to look for peak (first rain measurment to 48 hrs after)
e = sample((20*60):(48*60*60), n, replace=T) ##time to look for trough (between peak, or 6 hrs before last precip, and 20 min to 48 hrs after last precip)
f = sample((0):(72*60*60), n, replace=T) ##time to analyze recovery (at trough to 72 hours later)
g = runif(n, min=1, max=3.5) ##minimum standard deviations above or below the pre-strom trajectory to say a response occured

parameters = cbind(a,b,d,e,f,g) ##create a dataframe here to save the parameter values
storm.number.matrix = matrix(0,365,n)
flush.mag.matrix = matrix(0,365,n)
dilution.mag.matrix = matrix(0,365,n)
rate.recovery.matrix = matrix(0,365,n)
flush.mag.percent.matrix = matrix(0,365,n)
dilution.mag.percent.matrix = matrix(0,365,n)
interstorm.period.precip.matrix = matrix(0,365,n)
interstorm.period.sensor.matrix = matrix(0,365,n)
interstorm.dryness.matrix = matrix(0,365,n)
amount.precip.before.flush.matrix = matrix(0,365,n)
intensity.precip.before.flush.matrix = matrix(0,365,n)
max.precip.intensity.before.flush.matrix = matrix(0,365,n)
amount.precip.before.trough.matrix = matrix(0,365,n)
intensity.precip.before.trough.matrix = matrix(0,365,n)
max.precip.intensity.before.trough.matrix = matrix(0,365,n)
amount.total.precip.matrix = matrix(0,365,n)
intensity.total.precip.matrix = matrix(0,365,n)
max.precip.intensity.per.storm.matrix = matrix(0,365,n)
time.of.peak.matrix = matrix(0,365,n)
time.of.trough.matrix = matrix(0,365,n)
traj.sc.at.peak.matrix = matrix(0,365,n)
traj.sc.at.trough.matrix = matrix(0,365,n)
actual.sc.at.peak.matrix = matrix(0,365,n)
actual.sc.at.trough.matrix = matrix(0,365,n)
prestorm.slope.matrix = matrix(0,365,n)
prestorm.intercept.matrix = matrix(0,365,n)
recovery.intercept.matrix = matrix(0,365,n)

for (k in 1:n){

#-----Pull in Data from external files
#Precip Data
setwd(Precipfolder)
pdata = read.table("Just_what_I_need.txt", header=F, sep=",")
	#Add column names
		colnames(pdata) = c("Airport_Code","DateTime_UTC","AirTemp_C","RelHum_Per","WindSpeed_MPH","1HourPrecip_MM")
	#Next line will result in a warning when "M"s turn to "NA"s --- This is not a problem
		pdata[,6] = as.numeric(as.character(pdata[,6]))
#Sensor Data
setwd(Sensorfolder)
files = list.files()
sites = substr(files, 10, 12)
this.site = subset(files, sites==site1)
sdata = read.csv(this.site, header=T)
#re-write to match format of old data, which this code was designed around
sdata = cbind(sdata[,1:3], sdata[,5:6])

#-----Subset data by chosen time frame
begin = as.numeric(ISOdatetime(begin.year, begin.month, begin.day, begin.hour, begin.minute, begin.second, tz="UTC"))
end = as.numeric(ISOdatetime(end.year, end.month, end.day, end.hour, end.minute, end.second, tz="UTC"))
pdata[,2] = as.numeric(strptime(pdata[,2], format="%Y-%m-%d %H:%M", tz="UTC"))
pdata = subset(pdata, pdata[,2]>begin & pdata[,2]<end)
pdate = as.POSIXct(pdata[,2], origin="1970-01-01", tz="UTC")
sdata = subset(sdata, sdata[,2]>begin & sdata[,2]<end)
sdate = as.POSIXct(sdata[,2], origin="1970-01-01", tz="UTC")

#-----Subset precip data by available Sensor data (stops issues later in code)
if (min(pdate, na.rm=T)<min(sdate,na.rm=T)){
pdata = subset(pdata, pdata[,2]>=min(sdata[,2],na.rm=T)-20*60)
}
pdate = as.POSIXct(pdata[,2], origin="1970-01-01", tz="UTC")
pdate2 = strptime(pdate, format="%Y-%m-%d %H:%M:%S")

#-----Fix the precip to be actual value rather than accumulation and hourly reset
pdiff = pdata[2:(length(pdata[,6])),6] - pdata[1:(length(pdata[,6])-1),6]
pdiff = c(pdata[1,6], pdiff)
pdiff = ifelse(pdate2$min==15, pdata[,6], pdiff)
pdata[,6] = pdiff

#-----Subset precip data by rain events
rdata = subset(pdata, pdata[,6]>0) ##or > than a certain amount of precip per measurement
rdate = rdata[,2]

#-----Find temporal gaps between precip measurements and define storms by that gap
#make a matrix
storm.matrix = matrix(0,length(rdate),5)
colnames(storm.matrix) = c("TS", "Seconds since prev precip", "Storm number", "Total Precip for storm", "Max Precip Intensity for storm")
#fill in matrix column 1 with the rain time stamp info
storm.matrix[,1] = rdate
#fill in matrix column 2 with the time gap info. It is the time since previous precip, not the time until the next precip.
gap = (rdate[2:length(rdate)] - rdate[1:(length(rdate)-1)])
for (i in 1:(length(storm.matrix[,2])-1)){
	storm.matrix[i+1,2] = gap[i]
}
#number the storms --- j must be 1 in order for the storms to begin numbering at 1
j=1
for (i in 1:length(storm.matrix[,3])){
	if(storm.matrix[i,2]>(b[k])){	##parameter b
		j=j+1}
	storm.matrix[i,3] = j
}
#This determines the total precip per numbered storm event
precip.per.storm = tapply(rdata[,6], storm.matrix[,3], sum)
#This determines the max precip per 20 min per numbered storm event
max.precip.intensity.per.storm = tapply(rdata[,6], storm.matrix[,3], max)
#fill in the 4th column of the storm matrix with the total precip of that unique storm number and the 5th with the max precip intensity
for(i in 1:length(unique(storm.matrix[,3]))){
	storm.matrix[,4] = ifelse(storm.matrix[,3]==i, precip.per.storm[i], storm.matrix[,4])
	storm.matrix[,5] = ifelse(storm.matrix[,3]==i, max.precip.intensity.per.storm[i], storm.matrix[,5])
}

#-----Subset storms by total precip recorded for that storm
storm.matrix = subset(storm.matrix, storm.matrix[,4]>=a[k])  ##parameter a

#-----Reorder Unique storm numbers
uni.storms = unique(storm.matrix[,3])
for(i in 1:length(uni.storms)){
	storm.matrix[,3] = ifelse(storm.matrix[,3]==uni.storms[i], i, storm.matrix[,3])	
}

#-----Determine the VPD for each airport reading
vpd.matrix = matrix(0, length(pdata[,3]), 6)
colnames(vpd.matrix) = c("TS", "Air Temp", "Relative Humidity", "VPSAT", "VP", "VPD")
air.temp = pdata[,3]
relative.humidity = pdata[,4]
	air.temp = as.numeric(as.character(air.temp))
	relative.humidity = as.numeric(as.character(relative.humidity))
for (i in 1:length(air.temp)){
vpsat = (6.112*exp((17.67*air.temp[i])/(air.temp[i]+243.5)))*0.1 # [kPa]
vp = vpsat * (relative.humidity[i]/100)
vpd = vpsat - vp
vpd.matrix[i,1] = pdate [i]
vpd.matrix[i,2] = air.temp[i]
vpd.matrix[i,3] = relative.humidity[i]
vpd.matrix[i,4] = vpsat 
vpd.matrix[i,5] = vp 
vpd.matrix[i,6] = vpd 
}

#-----Subset sensor data by rain event range
for(i in 1:length(uni.storms)){
		this.storm.precip = subset(storm.matrix, storm.matrix[,3]==i)
		this.storm.sdata = subset(sdata, sdata[,2]<=max(this.storm.precip[,1], na.rm=TRUE) & sdata[,2]>=min(this.storm.precip[,1], na.rm=TRUE))
	if(i==1){
		new.sdata = this.storm.sdata 	
			if (length(this.storm.sdata[,1])>0){
				new.sdata["Storm_Number"] = i
			}
	}else { if(length(this.storm.sdata[,2])>0){
			if (length(this.storm.sdata[,1])>0){
		new.row = this.storm.sdata 
		new.row["Storm_Number"] = i
		new.sdata = rbind(new.sdata , new.row)
	}}}}

#-----Final list of Unique Storms
uni.storms = unique(new.sdata[,6])
for(i in 1:length(uni.storms)){
	new.sdata[,6] = ifelse(new.sdata[,6]==uni.storms[i], i, new.sdata[,6])	
}

#-----Find Peaks, Troughs, and Quantify Their Magnitudes

#-----Create Matrices
	#Make matrices for the observed peaks and troughs
peak.matrix = matrix(0, length(uni.storms), 2)
colnames(peak.matrix)=c("Time", "SpEC")
trough.matrix = matrix(0, length(uni.storms), 2)
colnames(trough.matrix)=c("Time", "SpEC")
	#Make a matrix for the rates of recovery
recovery.matrix = matrix(0, length(uni.storms), 2)
colnames(recovery.matrix)=c("Recovery Slope", "Recovery Intercept")
	#Make matrices for what the SC would have been at the peak and trough, if the SC followed the prestorm trajectory
traj.flush.matrix = matrix(0, length(uni.storms), 1)
colnames(traj.flush.matrix)=c("Projected SpEC at time of peak")
traj.dilution.matrix = matrix(0, length(uni.storms), 1)
colnames(traj.dilution.matrix)=c("Projected SpEC at time of trough")
	#Make matrices for the magnitude of the flush and dilution, the difference between the observed peak/trough and the trajectory peak/trough
mag.flush.matrix = matrix(0, length(uni.storms), 1)
colnames(mag.flush.matrix)=c("Difference SpEC")
mag.dilution.matrix = matrix(0, length(uni.storms), 1)
colnames(mag.dilution.matrix)=c("Difference SpEC")
	#Make matrices for the difference in % flush and dilution
percent.flush = matrix(0, length(uni.storms), 1)
colnames(percent.flush)=c("Percent SpEC Difference")
percent.dilution = matrix(0, length(uni.storms), 1)
colnames(percent.dilution)=c("Percent SpEC Difference")
	#Make a matrix for the time since previous storm
inter.storm.period.matrix =  matrix(0, length(uni.storms), 1)
colnames(inter.storm.period.matrix)=c("Time Since Previous Storm (sec) based on precip data")
	#Make a matrix for the cumulative vapor pressure defecit
cumulative.vpd.matrix = matrix(0, length(uni.storms), 2)
colnames(cumulative.vpd.matrix) = c("Time Since Previous Storm (sec) based on sensor data", "Cumulative VPD")
	#Make a matrix for the storm intesity data
intensity.matrix =  matrix(0, length(uni.storms), 6)
colnames(intensity.matrix)=c("Pre-Flush Intensity (mm/sec)", "Pre-Trough Intensity (mm/sec)", "Total Storm Intensity (mm/sec)", "Pre-Flush Max Intensity (mm/20 min)", "Pre-Trough Max Intensity(mm/20 min)", "Total Storm Max Intensity (mm/20 min)")

#-----Loop Through Unique Storms Begins
#loop through unique storm events
for (i in 1:length(uni.storms)){

#-----Find the Prestorm Trajectory
#separate window by time
	this.storm = subset(new.sdata, new.sdata[,6]==i)
	storm.begin = min(this.storm[,2], na.rm=TRUE)
	storm.end = max(this.storm[,2], na.rm=TRUE)
#If this ISN'T the first storm
	if(i!=min(uni.storms, na.rm=TRUE)){		
#Then grab the range between the first precip and parameter b earlier
		trajectory.window = subset(sdata, sdata[,2]>=storm.begin-(b[k]) & sdata[,2]<storm.begin) ##parameter b	
#If this IS the first storm
	} else{ if(i==min(uni.storms, na.rm=TRUE)){
#And the first sensor reading is EARLIER than the first precip minus the range for parameter b
			if(min(sdata[,2], na.rm=TRUE)<(storm.begin-(b[k]))){	##parameter b
#Then grab the range between the first precip and parameter b earlier
				trajectory.window = subset(sdata, sdata[,2]>=storm.begin-b[k] & sdata[,2]<storm.begin) ##parameter b
#Else, it is LATER than the first precip minus the range for parameter b
			} else{ if(min(sdata[,2], na.rm=TRUE)>=(storm.begin-b[k])){	##parameter b
#Then grab the range between the first sensor point and the first precip
				trajectory.window = subset(sdata, sdata[,2]>=min(sdata[,2], na.rm=TRUE) & sdata[,2]<storm.begin)
			}}
	}}
#If that window is greater than zero, continue
if(length(trajectory.window[,1])>0){
#find beginning of next storm
if(i!=max(uni.storms, na.rm=TRUE)){
		next.storm = subset(new.sdata, new.sdata[,6]==i+1)
			next.storm.begin = min(next.storm[,2], na.rm=TRUE)
	} else{ if (i==max(uni.storms, na.rm=TRUE)){ #if this is the last storm in the time frame, then go to the end of the window or the length of time that is "b", whichever is sooner
		end.time = max(sdata[,2], na.rm=TRUE) #the end of the chosen time frame
		storm.end.plus.b = storm.end+b[k] ##parameter b #the end of the storm plus b amount of time 
		next.storm.begin = min(c(end.time, storm.end.plus.b), na.rm=TRUE)
	}}
#find end of previous storm
if(i!=min(uni.storms, na.rm=TRUE)){
		prev.storm = subset(new.sdata, new.sdata[,6]==i-1)
			prev.storm.end = max(prev.storm[,2], na.rm=TRUE)
	} else{ if (i==min(uni.storms, na.rm=TRUE)){ #if this is the first storm in the time frame, then go to the beginning of the window or the length of time that is "b", whichever is later
		begin.time = min(sdata[,2], na.rm=TRUE) #the beginning of the chosen time frame
		storm.begin.minus.b = storm.begin-b[k] ##parameter b #the beginning of the storm minus "b" amount of time 
		prev.storm.end = max(c(begin.time, storm.begin.minus.b), na.rm=TRUE)
	}}
#ready for sen slope of all the points in that window (has to be x and y in zyp.sen, I think)
x = trajectory.window[,2] #This is the time axis
y = trajectory.window[,4] #This is the SC axis
intercept = zyp.sen(y~x)$coef[1]  #"b" in "y=mx+b"
slope = zyp.sen(y~x)$coef[2]  #"m" in "y=mx+b"
	prestorm.intercept = intercept
	prestorm.slope = slope

#-----Find Peaks and Troughs using Residuals from the prestorm trajectory
residuals.pre.storm = y - (x * prestorm.slope + prestorm.intercept)
#grabs the sensor data between this storm's start and the next storm's start
storm.residual.range = subset(sdata, sdata[,2]>=storm.begin & sdata[,2]<next.storm.begin)
range.sc = storm.residual.range[,4] #SC of the that time range
range.time = storm.residual.range[,2] #time stamp of the that time range
residuals.during = range.sc - (range.time * prestorm.slope + prestorm.intercept)
data.during = data.frame(range.time, range.sc, residuals.during)
flush.range = subset(data.during, data.during[,1]>=storm.begin & data.during[,1]<(storm.begin+d[k])) ##parameter d #Saying here that the flush has to occur within "d" amount of time hours following storm beginning 
flush.range = subset(flush.range, flush.range[,3]>(sd(residuals.pre.storm)*g[k])) ##parameter g #breaking that into those points that are greater than "g standard deviations" from the pre-storm trajectory
#Fix for storms that have no points outside of the standard deviation
if(length(flush.range[,1])>0){
	peak = subset(flush.range, flush.range[,2] == max(flush.range[,2], na.rm=TRUE))
	peak = subset(peak, peak[,1] == min(peak[,1], na.rm=TRUE))
	peak.matrix[i,1] = peak[,1] #Time Stamp
	peak.matrix[i,2] = peak [,2] #SC
} else { if(length(flush.range[,1])==0){
	peak.matrix[i,1] = NA
	peak.matrix[i,2] = NA
}}
if(is.na(peak.matrix[i,1])==FALSE){ ##If there is a peak, the trough must come after it. If there is not, it must come after the storm's last precip minus 6 hrs.
	dilution.range = subset(data.during, data.during[,1]<(storm.end+(e[k])) & data.during[,1]>(peak.matrix[i,1])) ##parameter e #Saying here that the trough has to occur after the storm's peak and within "e amount of time" following a storm's last precip.
} else { if (is.na(peak.matrix[i,1])==TRUE){
	dilution.range = subset(data.during, data.during[,1]<(storm.end+(e[k])) & data.during[,1]>storm.end-(6*60*60)) ##parameter e #Saying here that the trough has to occur after the storm's end minus 6 hrs and within "e amount of time" following a storm's last precip.
}}
dilution.range = subset(dilution.range, dilution.range[,3]<(sd(residuals.pre.storm)*-g[k])) ##parameter g #breaking that into those points that are greater than "-g standard deviations" from the pre-storm trajectory
if(length(dilution.range[,1])>0){
	trough = subset(dilution.range, dilution.range[,2] == min(dilution.range[,2], na.rm=TRUE))
	trough = subset(trough, trough[,1] == min(trough[,1]))
	trough.matrix[i,1] = trough[,1] #Time Stamp
	trough.matrix[i,2] = trough[,2] #SC
} else { if(length(dilution.range[,1])==0){
	trough.matrix[i,1] = NA
	trough.matrix[i,2] = NA
}}

#-----Determine the Trajectory of the Recovery
#take the window from the trough of the storm + "f"
if(!is.na(trough.matrix[i,1])){
	recovery.window = subset(sdata, sdata[,2]>=trough.matrix[i,1] & sdata[,2]<trough.matrix[i,1]+f[k]) #Saying here that the recovery window is after the trough until "f amount of time" after the trough ##parameter f
	x = recovery.window[,2] #This is the time axis
	y = recovery.window[,4] #This is the SC axis
	intercept = zyp.sen(y~x)$coef[1]
	slope = zyp.sen(y~x)$coef[2]
		recovery.intercept = intercept #saving for plotting purposes
		recovery.slope = slope #saving for plotting purposes
	recovery.matrix[i,1] = recovery.slope
	recovery.matrix[i,2] = recovery.intercept
} else { if (is.na(trough.matrix[i,1])){
	recovery.matrix[i,1] = NA
	recovery.matrix[i,2] = NA
}}
} else { if(length(trajectory.window[,1])<=0) {
	peak.matrix[i,1] = NA
	peak.matrix[i,2] = NA
	trough.matrix[i,1] = NA
	trough.matrix[i,2] = NA
	recovery.matrix[i,1] = NA
	recovery.matrix[i,2] = NA
}}

#-----Quanitfy the amount of Precip Before the Flush
	rain.events.before.flush = subset(rdata, rdata[,2]>=storm.begin & rdata[,2]<peak.matrix[i,1])
	precip.before.flush = sum(rain.events.before.flush[,6], na.rm=TRUE)
		
#-----Quanitfy the amount of Precip Before the Trough
	rain.events.before.trough = subset(rdata, rdata[,2]>=storm.begin & rdata[,2]<trough.matrix[i,1])
	precip.before.trough = sum(rain.events.before.trough[,6], na.rm=TRUE)

#-----Quanitfy the Total Precip amount for the whole storm
	total.storm.precip = unique(subset(storm.matrix, storm.matrix[,3]==i)[,4])
		#-----Find the SC at the time of the peaks and troughs if the prestorm trajectory was followed (find "y"s on the prestorm trajectory line, "y=mx+b")
		traj.flush.matrix[i] = prestorm.slope * peak.matrix [i,1] + prestorm.intercept
		traj.dilution.matrix[i] = prestorm.slope * trough.matrix [i,1] + prestorm.intercept
		#-----Quanitfy the difference in observed SC and trajectory SC (value)
		mag.flush.matrix[i] = peak.matrix [i,2] - traj.flush.matrix[i]
		mag.dilution.matrix[i] = trough.matrix [i,2] - traj.dilution.matrix[i]
		#-----Quanitfy the difference in observed SC and trajectory SC (percent)
		percent.flush[i] = ( (peak.matrix [i,2] - traj.flush.matrix[i]) / (traj.flush.matrix[i]) )*100
		percent.dilution[i] = ( (trough.matrix [i,2] - traj.dilution.matrix[i]) / (traj.dilution.matrix[i]) )*100
		#-----Find the seconds since the previous storm ended (last rain measurment)
		inter.storm.period = subset(storm.matrix, storm.matrix[,3] == i)
		inter.storm.period = subset(inter.storm.period, inter.storm.period[,1] == min(inter.storm.period[,1], na.rm=TRUE))
		inter.storm.period.matrix[i] = inter.storm.period[2]
		#-----Determine the Drying Pressure / Interstorm Dryness / Cumulative VPD between each storm
		##the time between storms will be different here, as it's using the closest sensor measurment for time, not the actual precip times
		vpd.matrix.range = subset(vpd.matrix, vpd.matrix[,1]<storm.begin & vpd.matrix[,1]>prev.storm.end) ##range of last storm to this storm
	if (length(vpd.matrix.range[,1])>1){
		vpd.range.begin = vpd.matrix.range[1,1] ##beginning of that range
		vpd.range.end = vpd.matrix.range[length(vpd.matrix.range[,1]),1] ##end of that range
		backbone = seq(vpd.range.begin, vpd.range.end, by=60) ##series of times where I want an approximation of VPD
		vpd.estimate = approx(vpd.matrix.range[,1], vpd.matrix.range[,6], backbone)
		cumulative.vpd.matrix[i,1] = vpd.range.begin - vpd.range.end ##storm range based on sensor data time stamp
		cumulative.vpd.matrix[i,2] = sum(vpd.estimate$y, na.rm=TRUE) ##cumulative vpd at a linearly interpolated 1 min series
	} else{
		cumulative.vpd.matrix[i,1] = NA
		cumulative.vpd.matrix[i,2] = NA
	}
		#-----Quantify the storm intensity (mm/sec of precip)
		intensity.matrix[i,1] = precip.before.flush/(peak.matrix [i,1]-storm.begin)
		intensity.matrix[i,2] = precip.before.trough/(trough.matrix [i,1]-storm.begin)
		intensity.matrix[i,3] = total.storm.precip/(storm.end-storm.begin)
		intensity.matrix[i,4] = max(rain.events.before.flush[,6], na.rm=TRUE)
		intensity.matrix[i,5] = max(rain.events.before.trough[,6], na.rm=TRUE)
		intensity.matrix[i,6] = max.precip.intensity.per.storm[i]

#-----Changing Time Format for storm to DOY
storm.begin.doy = strptime(as.POSIXct(storm.begin, origin="1970-01-01"), format="%Y-%m-%d")

#-----Populating the DOY matrices
storm.number.matrix[storm.begin.doy$yday+1,k] = i
flush.mag.matrix[storm.begin.doy$yday+1,k] = mag.flush.matrix[i]
dilution.mag.matrix[storm.begin.doy$yday+1,k] = mag.dilution.matrix[i]
rate.recovery.matrix[storm.begin.doy$yday+1,k] = recovery.matrix[i,1]
flush.mag.percent.matrix[storm.begin.doy$yday+1,k] = percent.flush[i]
dilution.mag.percent.matrix[storm.begin.doy$yday+1,k] = percent.dilution[i]
interstorm.period.precip.matrix[storm.begin.doy$yday+1,k] = inter.storm.period.matrix[i]
interstorm.period.sensor.matrix[storm.begin.doy$yday+1,k] = cumulative.vpd.matrix[i,1]
interstorm.dryness.matrix[storm.begin.doy$yday+1,k] = cumulative.vpd.matrix[i,2]
amount.precip.before.flush.matrix[storm.begin.doy$yday+1,k] = precip.before.flush
intensity.precip.before.flush.matrix[storm.begin.doy$yday+1,k] = intensity.matrix[i,1]
max.precip.intensity.before.flush.matrix[storm.begin.doy$yday+1,k] = intensity.matrix[i,4]
amount.precip.before.trough.matrix[storm.begin.doy$yday+1,k] = precip.before.trough
intensity.precip.before.trough.matrix[storm.begin.doy$yday+1,k] = intensity.matrix[i,2]
max.precip.intensity.before.trough.matrix[storm.begin.doy$yday+1,k] = intensity.matrix[i,5]
amount.total.precip.matrix[storm.begin.doy$yday+1,k] = total.storm.precip
intensity.total.precip.matrix[storm.begin.doy$yday+1,k] = intensity.matrix[i,3]
max.precip.intensity.per.storm.matrix[storm.begin.doy$yday+1,k] = intensity.matrix[i,6]
time.of.peak.matrix[storm.begin.doy$yday+1,k] = peak.matrix[i,1]
time.of.trough.matrix[storm.begin.doy$yday+1,k] = trough.matrix[i,1]
traj.sc.at.peak.matrix[storm.begin.doy$yday+1,k] = prestorm.slope * traj.flush.matrix[i] + prestorm.intercept
traj.sc.at.trough.matrix[storm.begin.doy$yday+1,k] = prestorm.slope * traj.dilution.matrix[i] + prestorm.intercept
actual.sc.at.peak.matrix[storm.begin.doy$yday+1,k] = peak.matrix[i,2]
actual.sc.at.trough.matrix[storm.begin.doy$yday+1,k] = trough.matrix[i,2]
prestorm.slope.matrix[storm.begin.doy$yday+1,k] = prestorm.slope
prestorm.intercept.matrix[storm.begin.doy$yday+1,k] = prestorm.intercept
recovery.intercept.matrix[storm.begin.doy$yday+1,k] = recovery.matrix[i,2]

#-----Loop Through Unique Storms Ends with the "}" Below
}
#-----Loop Through Variable Parameters Ends with the "}" Below
}

#-----Create frequency matrices to pick out storms by percent of dependent responses compared to storms chosen
doy= 1:365
freq.flush.mag.matrix = matrix(0,365,2)
freq.dilution.mag.matrix = matrix(0,365,2)
freq.rate.recovery.matrix = matrix(0,365,2)
freq.interstorm.period.precip.matrix = matrix(0,365,2)

#-----Column 1
freq.flush.mag.matrix[,1] = doy
freq.dilution.mag.matrix[,1] = doy
freq.rate.recovery.matrix[,1] = doy
freq.interstorm.period.precip.matrix[,1] = doy

#-----Column 2
for (m in 1:length(doy)){
freq = sum(flush.mag.matrix[m,]!=0, na.rm=TRUE)
freq.flush.mag.matrix[m,2] = freq
freq = sum(dilution.mag.matrix[m,]!=0, na.rm=TRUE)
freq.dilution.mag.matrix[m,2] = freq
freq = sum(rate.recovery.matrix[m,]!=0, na.rm=TRUE)
freq.rate.recovery.matrix[m,2] = freq
freq = sum(interstorm.period.precip.matrix[m,]!=0, na.rm=TRUE)
freq.interstorm.period.precip.matrix[m,2] = freq
}
frequency.matrix = cbind(
doy,
freq.flush.mag.matrix[,2],
freq.dilution.mag.matrix[,2],
freq.rate.recovery.matrix[,2],
freq.interstorm.period.precip.matrix[,2]
)
colnames(frequency.matrix)=(c("doy", "mag.flush", "mag.dilution", "rate.recovery", 
"inter.storm.period"))

#-----SAVE TO TABLES
setwd(Run.Save)
write.csv(parameters, file="parameters.csv", row.names=FALSE)
write.csv(frequency.matrix, file="frequency.matrix.csv", row.names=FALSE)
write.csv(storm.number.matrix, file="storm.number.matrix.csv", row.names=FALSE)
write.csv(flush.mag.matrix, file="flush.mag.matrix.csv", row.names=FALSE)
write.csv(dilution.mag.matrix, file="dilution.mag.matrix.csv", row.names=FALSE)
write.csv(rate.recovery.matrix, file="rate.recovery.matrix.csv", row.names=FALSE)
write.csv(flush.mag.percent.matrix, file="flush.mag.percent.matrix.csv", row.names=FALSE)
write.csv(dilution.mag.percent.matrix, file="dilution.mag.percent.matrix.csv", row.names=FALSE)
write.csv(interstorm.period.precip.matrix, file="interstorm.period.precip.matrix.csv", row.names=FALSE)
write.csv(interstorm.period.sensor.matrix, file="interstorm.period.sensor.matrix.csv", row.names=FALSE)
write.csv(interstorm.dryness.matrix, file="interstorm.dryness.matrix.csv", row.names=FALSE)
write.csv(amount.precip.before.flush.matrix, file="amount.precip.before.flush.matrix.csv", row.names=FALSE)
write.csv(intensity.precip.before.flush.matrix, file="intensity.precip.before.flush.matrix.csv", row.names=FALSE)
write.csv(max.precip.intensity.before.flush.matrix, file="max.precip.intensity.before.flush.matrix.csv", row.names=FALSE)
write.csv(amount.precip.before.trough.matrix, file="amount.precip.before.trough.matrix.csv", row.names=FALSE)
write.csv(intensity.precip.before.trough.matrix, file="intensity.precip.before.trough.matrix.csv", row.names=FALSE)
write.csv(max.precip.intensity.before.trough.matrix, file="max.precip.intensity.before.trough.matrix.csv", row.names=FALSE)
write.csv(amount.total.precip.matrix, file="amount.total.precip.matrix.csv", row.names=FALSE)
write.csv(intensity.total.precip.matrix, file="intensity.total.precip.matrix.csv", row.names=FALSE)
write.csv(max.precip.intensity.per.storm.matrix, file="max.precip.intensity.per.storm.matrix.csv", row.names=FALSE)
write.csv(time.of.peak.matrix, file="time.of.peak.matrix.csv", row.names=FALSE)
write.csv(time.of.trough.matrix, file="time.of.trough.matrix.csv", row.names=FALSE)
write.csv(traj.sc.at.peak.matrix, file="traj.sc.at.peak.matrix.csv", row.names=FALSE)
write.csv(traj.sc.at.trough.matrix, file="traj.sc.at.trough.matrix.csv", row.names=FALSE)
write.csv(actual.sc.at.peak.matrix, file="actual.sc.at.peak.matrix.csv", row.names=FALSE)
write.csv(actual.sc.at.trough.matrix, file="actual.sc.at.trough.matrix.csv", row.names=FALSE)
write.csv(prestorm.slope.matrix, file="prestorm.slope.matrix.csv", row.names=FALSE)
write.csv(prestorm.intercept.matrix, file="prestorm.intercept.matrix.csv", row.names=FALSE)
write.csv(recovery.intercept.matrix, file="recovery.intercept.matrix.csv", row.names=FALSE)
} #end of function
#--------------------------------------------------------------------------------
entire.code.compiled <- cmpfun(entire.code) #compile the code
entire.code.compiled(10000)
#--------------------------------------------------------------------------------
